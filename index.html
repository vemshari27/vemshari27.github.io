<!DOCTYPE HTML>
<html>

<head>
  <!-- Google analytics tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-WRYQ3GG5Y8"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-STGLQW4BJX');

    function toggleExcerpt(elementId) {
      const excerptDiv = document.getElementById(elementId);
      if (excerptDiv.style.display === "none") {
        excerptDiv.style.display = "block";
      } else {
        excerptDiv.style.display = "none";
      }
    }
  </script>

  <link rel="icon" type="image/png" href="images/favicon.png" />

  <!-- Title -->
  <title>Srihari Vemuru</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=1000">

  <!-- Isotope JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
  <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

  <!-- Custom Style -->
  <link rel="stylesheet" href="style.css">

  <!-- Google Font -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap"
    rel="stylesheet">
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');
  </style>
</head>

<body id="body">

  <div id="main">
    <div id="intro">
      <div id="intro-text">
        <h1>Srihari Vemuru</h1>
        <p>
          Hi! I am a PhD student in Mechanical Engineering at Iowa State University, advised by Dr. Sourabh Bhattacharya. 
          My research focuses on multi-robot planning using reinforcement learning (RL) and robotic perception. 
          I have hands-on experience working with UAVs, UGVs, and quadruped robots. My work integrates RL and computer vision 
          into path planning frameworks to tackle game-theoretic challenges in multi-agent systems.
          <br><br>
          <!-- In PhD program:
            Hi :wave: I am Liyiming Ke, 柯丽一鸣, or "Kay". I am a final-year grad student at University of Washington, advised by [Siddhartha Srinivasa](https://goodrobot.ai/). I research on Robotics :robot: Learning, with a focus on **Data-Driven Fine Manipulation**.
            As a test-bed for pushing the limit of fine manipulation, I built [a chopsticks robot](https://goodcherrybot.github.io/) to showcase the _precision_ and _dynamic reactivity_ of systems trained via reinforcement learning. I have also developed theories like [f-divergence framework for imitation learning and adversarial imitation learning](https://arxiv.org/abs/1905.12888) and [leveraging local-continuity in dynamics](https://arxiv.org/pdf/2310.12972).
            I was very fortunate to work with [Abhishek Gupta](https://homes.cs.washington.edu/~abhgupta/), [Tapomayukh Bhattacharjee](https://robotics.cornell.edu/faculty/tapomayukh-bhattacharjee-bio/), [Byron Boots](https://homes.cs.washington.edu/~bboots/) and [Sanjiban Choudary](https://sanjibanchoudhury.com/).
          -->
        <!-- <div id="more-bio" style="display: None">
          <br>
          <p>Liyiming Ke is a full stack robotist at Physical Intelligence researching on Machine Learning for Robot
            Manipulation. She earned her Ph.D. from the University of Washington with her thesis titled "Data-driven
            Fine Manipulation". She built a chopsticks-welding robot that demonstrate fine motor skills and developed
            theoretical frameworks for robot learning. She has led human-robot interactive demonstration at AAAS in 2020
            and has been selected as one of the Rising Stars in EECS 2023.</p>
        </div> -->
        <br>
        <!-- <a href="javascript:toggle_bio()">Formal Bio</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
        <a href="https://scholar.google.com/citations?user=qHaTOIoAAAAJ&hl=en">G. Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://github.com/vemshari27">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://www.linkedin.com/in/srihari-vemuru/">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <br><br>
        vemshari@iastate.edu
        <br><br>
        </p>
      </div>
      <div id="intro-image">
        <img src="images/profile.jpeg">
      </div>
    </div>


    <div class="grid">
      <!-- Publications -->

      <div class="list-item publication" data-category="publication">
        <a class="thumbnail">
          <video playsinline="" muted="" autoplay="" loop="" width="180px">
            <source src="images/FUEL_submission.mp4" type="video/mp4">
          </video>
        </a>
        <div class="project-description">
          <h3><a> Reinforcement Learning for UAV-UGV Multi-agent Planning</a></h3>
          <p>
            Reinforcement learning (RL) agents for delivery task execution, enabling adaptive decision-making in complex, partially observable environments. Algortithms
            like SARSA, DQN, A2C and PPO are used to train agents for UAV-UGV multi-agent planning tasks.
            The agents learn to navigate and collaborate in dynamic environments, enhancing their performance through continuous learning and adaptation.
          </p>
        </div>
      </div>

      <div class="list-item publication" data-category="publication">
        <a class="thumbnail">
          <img src="images/showcase.png" alt="Showcase Thumbnail" width="180px">
        </a>
        <div class="project-description">
          <h3><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4829514"> Localization-based Stationary Object Tracking in Precision Agriculture</a></h3>
          <p>
            Designed a novel object tracking system based on Simultaneous Localization and Mapping (SLAM), which significantly improved tracking performance in dynamic robotic scenarios. This model surpassed existing state-of-the-art trackers by 30.9%, making it a valuable tool for robots operating in cluttered and rapidly changing environments. The project advanced real-time perception capabilities in robotics by combining object tracking with spatial mapping.
          </p>
        </div>
      </div>

      <div class="list-item publication" data-category="publication">
        <a class="thumbnail">
          <video playsinline="" muted="" autoplay="" loop="" width="180px">
            <source src="images/mango_drone.mp4" type="video/mp4">
          </video>
        </a>
        <div class="project-description">
          <h3><a> Multi-agent collaborative framework for agriculture</a></h3>
          <p>
            Autonomous framework to detect anomalies (e.g., pests, weeds, deficiency, etc.) in a plantation setting and intervene to resolve them using a group of UAVs and UGVs. Given the regions of interest in a farm, where robotic interventions are required (e.g., watering, spraying, harvesting), the goal is to plan optimal routes for the heterogenous team of UAVs and UGVs. Each agent has specialized tools, and the tasks must be optimally assigned and executed. Given that the farms are largely unstructured and dynamically changing (e.g., wind), an efficient real-time planner is required for enabling the team of UAVs and UGVs to accurately reach the locations of interest to perform operations like spraying and harvesting.
          </p>
        </div>
      </div>

      <div class="list-item publication" data-category="publication">
        <a class="thumbnail">
          <img src="images/brain3.png" alt="Showcase Thumbnail" width="180px">
        </a>
        <div class="project-description">
          <h3><a> Medical AI: Sleep Apnea Detection Using Multimodal Learning</a></h3>
          <p>
            Built a classification model to diagnose obstructive sleep apnea by integrating head CT imaging data with patient health records. The multimodal learning approach achieved an impressive 95% accuracy in classification, offering a promising solution for early and accurate detection of sleep apnea. This project contributed to advancing biomedical AI, particularly in the domain of personalized healthcare.
          </p>
        </div>
      </div>

      <div class="list-item publication" data-category="publication">
        <a class="thumbnail">
          <img src="images/chest.png" alt="Showcase Thumbnail" width="180px">
        </a>
        <div class="project-description">
          <h3><a> Chest Disease Recognition</a></h3>
            <p>
            Developed an AI system for comprehensive chest disease recognition from chest X-ray images. The model takes both the X-ray image and auxiliary patient information as input, and generates a detailed radiological report describing the findings. The architecture combines CNNs and DNNs to extract features, which are then fused using a feature combination network. An LSTM or Transformer-based model is used to generate the textual analysis. Additionally, the project explores advanced representation learning techniques to improve diagnostic accuracy and interpretability.
          </p>
        </div>
      </div>


    </div>
    <div id="footer">
      Website template by <a href="https://andyzeng.github.io/">Andy Zeng</a> and <a
        href="https://jonbarron.info/">Jon's
        website</a>.
    </div>

  </div>

  <script>

    // Isotope grid.
    var $grid = $('.grid').isotope({
      itemSelector: '.list-item',
      layoutMode: 'fitRows',
      transitionDuration: 0,
      stagger: 10,
      initLayout: false,
      getSortData: {
        name: '.name',
        symbol: '.symbol',
        number: '.number parseInt',
        category: '[data-category]',
        weight: function (itemElem) {
          var weight = $(itemElem).find('.weight').text();
          return parseFloat(weight.replace(/[\(\)]/g, ''));
        }
      }
    });

    // Bind filter button click.
    $('#filters').on('click', 'button', function () {
      var filterValue = $(this).attr('data-filter');
      localStorage.setItem('filterValue', filterValue);
      $grid.isotope({ filter: filterValue });
    });

    // Change is-checked class on buttons.
    $('.button-group').each(function (i, buttonGroup) {
      var $buttonGroup = $(buttonGroup);
      $buttonGroup.on('click', 'button', function () {
        $buttonGroup.find('.is-checked').removeClass('is-checked');
        $(this).addClass('is-checked');
      });
    });

    function update_isotope() {
      // Retrieve cached button click.
      var defaultFilterValue = localStorage.getItem('filterValue');
      if (defaultFilterValue == null) {
        defaultFilterValue = ".publication"  // Changed from ".highlight" to ".publication"
      }
      $grid.isotope({ filter: defaultFilterValue });
      var buttons = document.getElementsByClassName("button");
      for (var currButton of buttons) {
        if (currButton.getAttribute('data-filter') == defaultFilterValue) {
          currButton.classList.add('is-checked');
        } else {
          currButton.classList.remove('is-checked');
        }
      }
    }

    function toggle_bio() {
      var x = document.getElementById("more-bio");
      if (x.style.display === "none") {
        x.style.display = "block";
      } else {
        x.style.display = "none";
      }
    }

    function toggle_highlights() {
      var x = document.getElementById("main-highlights");
      var y = document.getElementById("more-highlights");
      var b = document.getElementById("toggle_highlights_button")
      if (y.style.display === "none") {
        x.style.display = "none";
        y.style.display = "block";
        b.innerHTML = "Show less"
        update_isotope();
      } else {
        x.style.display = "block";
        y.style.display = "none";
        b.innerHTML = "Show more"
        update_isotope();
      }
    }

    update_isotope();

  </script>
</body>

</html>